{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is just for creating paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# General Purpose Paths\n",
    "data_small_path = os.path.join('data','data_small.csv')\n",
    "data_big_path = os.path.join('data','data_big.csv')\n",
    "results_path = 'results'\n",
    "scripts_path = 'scripts'\n",
    "\n",
    "# Ex1 - Paths\n",
    "mapper_path_ex1 = os.path.join(scripts_path,'Ex1_mapper.py')\n",
    "reducer_path_ex1 = os.path.join(scripts_path,'Ex1_reducer.py')\n",
    "results_ex1_mapred_path = os.path.join(results_path,'Ex1-MapRed')\n",
    "\n",
    "# Ex2 - Paths\n",
    "mapper_path_ex2 = os.path.join(scripts_path,'Ex2_mapper.py')\n",
    "reducer_path_ex2 = os.path.join(scripts_path,'Ex2_reducer.py')\n",
    "results_ex2_mapred_path = os.path.join(results_path,'Ex2-MapRed')\n",
    "\n",
    "# Ex3 - Paths\n",
    "mapper_path_ex3 = os.path.join(scripts_path,'Ex3_mapper.py')\n",
    "reducer_path_ex3 = os.path.join(scripts_path,'Ex3_reducer.py')\n",
    "results_ex3_mapred_path = os.path.join(results_path,'Ex3-MapRed')\n",
    "\n",
    "# Create result directory from scratch\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "if not os.path.exists(scripts_path):\n",
    "    os.makedirs(scripts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Create an inverted index with the following structure:\n",
    "\n",
    "- Continent - Count of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex1_mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%file {mapper_path_ex1}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "# Utility function\n",
    "def Emit(key: str, value: str, sep='\\t'):\n",
    "    \"\"\"\n",
    "    Emmits a key-value pair.\n",
    "    \"\"\"\n",
    "    message = f'{key}' + sep + f'{value}'\n",
    "    print(message)\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split(\",\")\n",
    "    continent = words[5]\n",
    "    occurrences = words[9]\n",
    "    Emit(str(continent),str(occurrences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex1_reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%file {reducer_path_ex1}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "# Utility function\n",
    "def Emit(key: str, value: str, sep='\\t'):\n",
    "    \"\"\"\n",
    "    Emmits a key-value pair.\n",
    "    \"\"\"\n",
    "    message = f'{key}' + sep + f'{value}'\n",
    "    print(message)\n",
    "    \n",
    "\n",
    "is_first_continent = True\n",
    "count = 0\n",
    "curr_continent = ''\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # split the line into words\n",
    "    continent,occurences = line.split(\"\\t\")\n",
    "    \n",
    "    if is_first_continent:\n",
    "        curr_continent = continent\n",
    "        count = int(occurences)\n",
    "        is_first_continent = False\n",
    "        \n",
    "    elif curr_continent == continent:\n",
    "        count += int(occurences)\n",
    "    else:\n",
    "        Emit(curr_continent,str(count))\n",
    "        count = 1\n",
    "        curr_continent = continent\n",
    "\n",
    "Emit(curr_continent, str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:33:20,211 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2019-11-16 15:33:20,554 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2019-11-16 15:33:20,554 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2019-11-16 15:33:20,606 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-16 15:33:20,993 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2019-11-16 15:33:21,052 INFO mapreduce.JobSubmitter: number of splits:7\n",
      "2019-11-16 15:33:21,510 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1890731080_0001\n",
      "2019-11-16 15:33:21,511 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2019-11-16 15:33:21,735 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2019-11-16 15:33:21,740 INFO mapreduce.Job: Running job: job_local1890731080_0001\n",
      "2019-11-16 15:33:21,754 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2019-11-16 15:33:21,762 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2019-11-16 15:33:21,776 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:21,776 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:21,900 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2019-11-16 15:33:21,909 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000000_0\n",
      "2019-11-16 15:33:21,995 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:21,999 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:22,045 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:33:22,072 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:0+33554432\n",
      "2019-11-16 15:33:22,135 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:33:22,212 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:33:22,212 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:33:22,212 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:33:22,213 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:33:22,213 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:33:22,220 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:33:22,243 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:33:22,256 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2019-11-16 15:33:22,263 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2019-11-16 15:33:22,268 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2019-11-16 15:33:22,269 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2019-11-16 15:33:22,272 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2019-11-16 15:33:22,272 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2019-11-16 15:33:22,274 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2019-11-16 15:33:22,275 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2019-11-16 15:33:22,276 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2019-11-16 15:33:22,278 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2019-11-16 15:33:22,279 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2019-11-16 15:33:22,280 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2019-11-16 15:33:22,349 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:22,351 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:22,355 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:22,370 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:22,444 INFO streaming.PipeMapRed: Records R/W=2537/1\n",
      "2019-11-16 15:33:22,564 INFO streaming.PipeMapRed: R/W/S=10000/3364/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:22,773 INFO mapreduce.Job: Job job_local1890731080_0001 running in uber mode : false\n",
      "2019-11-16 15:33:22,775 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2019-11-16 15:33:23,805 INFO streaming.PipeMapRed: R/W/S=100000/90652/0 in:100000=100000/1 [rec/s] out:90653=90653/1 [rec/s]\n",
      "2019-11-16 15:33:24,930 INFO streaming.PipeMapRed: R/W/S=200000/189285/0 in:100000=200000/2 [rec/s] out:94643=189287/2 [rec/s]\n",
      "2019-11-16 15:33:26,135 INFO streaming.PipeMapRed: R/W/S=300000/292186/0 in:100000=300000/3 [rec/s] out:97395=292186/3 [rec/s]\n",
      "2019-11-16 15:33:26,398 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:33:26,489 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:33:26,507 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:33:26,507 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:33:26,507 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:33:26,507 INFO mapred.MapTask: bufstart = 0; bufend = 2798727; bufvoid = 104857600\n",
      "2019-11-16 15:33:26,507 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939532(99758128); length = 1274865/6553600\n",
      "2019-11-16 15:33:27,134 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:33:27,173 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000000_0 is done. And is in the process of committing\n",
      "2019-11-16 15:33:27,181 INFO mapred.LocalJobRunner: Records R/W=2537/1\n",
      "2019-11-16 15:33:27,182 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000000_0' done.\n",
      "2019-11-16 15:33:27,221 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33735999\n",
      "\t\tFILE: Number of bytes written=4132049\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318717\n",
      "\t\tMap output records=318717\n",
      "\t\tMap output bytes=2798727\n",
      "\t\tMap output materialized bytes=3436167\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318717\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=176685056\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:33:27,225 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000000_0\n",
      "2019-11-16 15:33:27,233 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000001_0\n",
      "2019-11-16 15:33:27,241 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:27,243 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:27,245 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:33:27,254 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:33554432+33554432\n",
      "2019-11-16 15:33:27,314 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:33:27,380 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:33:27,380 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:33:27,381 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:33:27,381 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:33:27,381 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:33:27,383 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:33:27,398 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:33:27,454 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:27,454 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:27,461 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:27,494 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:27,565 INFO streaming.PipeMapRed: Records R/W=1921/1\n",
      "2019-11-16 15:33:27,669 INFO streaming.PipeMapRed: R/W/S=10000/4584/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:27,805 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:33:29,178 INFO streaming.PipeMapRed: R/W/S=100000/91885/0 in:100000=100000/1 [rec/s] out:91886=91886/1 [rec/s]\n",
      "2019-11-16 15:33:30,994 INFO streaming.PipeMapRed: R/W/S=200000/191240/0 in:66666=200000/3 [rec/s] out:63747=191242/3 [rec/s]\n",
      "2019-11-16 15:33:32,650 INFO streaming.PipeMapRed: R/W/S=300000/289673/0 in:60000=300000/5 [rec/s] out:57934=289673/5 [rec/s]\n",
      "2019-11-16 15:33:33,000 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:33:33,131 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:33:33,131 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:33:33,135 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:33:33,135 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:33:33,135 INFO mapred.MapTask: bufstart = 0; bufend = 2797280; bufvoid = 104857600\n",
      "2019-11-16 15:33:33,135 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939868(99759472); length = 1274529/6553600\n",
      "2019-11-16 15:33:33,468 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:33:33,474 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000001_0 is done. And is in the process of committing\n",
      "2019-11-16 15:33:33,483 INFO mapred.LocalJobRunner: Records R/W=1921/1\n",
      "2019-11-16 15:33:33,483 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000001_0' done.\n",
      "2019-11-16 15:33:33,484 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67295264\n",
      "\t\tFILE: Number of bytes written=7566633\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318633\n",
      "\t\tMap output records=318633\n",
      "\t\tMap output bytes=2797280\n",
      "\t\tMap output materialized bytes=3434552\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318633\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=278396928\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:33:33,486 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000001_0\n",
      "2019-11-16 15:33:33,486 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000002_0\n",
      "2019-11-16 15:33:33,493 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:33,494 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:33,495 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:33:33,501 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:67108864+33554432\n",
      "2019-11-16 15:33:33,550 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:33:33,604 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:33:33,604 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:33:33,605 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:33:33,605 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:33:33,605 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:33:33,606 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:33:33,620 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:33:33,711 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:33,712 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:33,713 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:33,716 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:33,805 INFO streaming.PipeMapRed: Records R/W=2476/1\n",
      "2019-11-16 15:33:33,926 INFO streaming.PipeMapRed: R/W/S=10000/3772/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:35,554 INFO streaming.PipeMapRed: R/W/S=100000/91404/0 in:100000=100000/1 [rec/s] out:91405=91405/1 [rec/s]\n",
      "2019-11-16 15:33:38,179 INFO streaming.PipeMapRed: R/W/S=200000/191442/0 in:50000=200000/4 [rec/s] out:47860=191442/4 [rec/s]\n",
      "2019-11-16 15:33:41,432 INFO streaming.PipeMapRed: R/W/S=300000/291022/0 in:42857=300000/7 [rec/s] out:41574=291022/7 [rec/s]\n",
      "2019-11-16 15:33:42,266 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:33:42,541 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:33:42,542 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:33:42,544 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:33:42,544 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:33:42,544 INFO mapred.MapTask: bufstart = 0; bufend = 2796979; bufvoid = 104857600\n",
      "2019-11-16 15:33:42,545 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939788(99759152); length = 1274609/6553600\n",
      "2019-11-16 15:33:42,859 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "2019-11-16 15:33:43,155 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:33:43,175 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000002_0 is done. And is in the process of committing\n",
      "2019-11-16 15:33:43,191 INFO mapred.LocalJobRunner: Records R/W=2476/1\n",
      "2019-11-16 15:33:43,192 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000002_0' done.\n",
      "2019-11-16 15:33:43,193 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=100854529\n",
      "\t\tFILE: Number of bytes written=11000956\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318653\n",
      "\t\tMap output records=318653\n",
      "\t\tMap output bytes=2796979\n",
      "\t\tMap output materialized bytes=3434291\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318653\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=383778816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:33:43,193 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000002_0\n",
      "2019-11-16 15:33:43,193 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000003_0\n",
      "2019-11-16 15:33:43,233 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:43,233 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:43,234 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:33:43,245 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:100663296+33554432\n",
      "2019-11-16 15:33:43,348 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:33:43,673 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:33:43,674 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:33:43,674 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:33:43,674 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:33:43,674 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:33:43,697 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:33:43,779 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:33:43,832 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:43,833 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:43,834 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:43,836 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:33:43,860 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:33:44,125 INFO streaming.PipeMapRed: Records R/W=2460/1\n",
      "2019-11-16 15:33:44,283 INFO streaming.PipeMapRed: R/W/S=10000/4646/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:46,494 INFO streaming.PipeMapRed: R/W/S=100000/88180/0 in:50000=100000/2 [rec/s] out:44090=88180/2 [rec/s]\n",
      "2019-11-16 15:33:49,523 INFO streaming.PipeMapRed: R/W/S=200000/189930/0 in:40000=200000/5 [rec/s] out:37986=189930/5 [rec/s]\n",
      "2019-11-16 15:33:52,381 INFO streaming.PipeMapRed: R/W/S=300000/291474/0 in:37500=300000/8 [rec/s] out:36434=291474/8 [rec/s]\n",
      "2019-11-16 15:33:52,909 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:33:53,077 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:33:53,078 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:33:53,078 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:33:53,078 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:33:53,078 INFO mapred.MapTask: bufstart = 0; bufend = 2797072; bufvoid = 104857600\n",
      "2019-11-16 15:33:53,078 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940072(99760288); length = 1274325/6553600\n",
      "2019-11-16 15:33:53,352 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:33:53,367 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000003_0 is done. And is in the process of committing\n",
      "2019-11-16 15:33:53,374 INFO mapred.LocalJobRunner: Records R/W=2460/1\n",
      "2019-11-16 15:33:53,375 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000003_0' done.\n",
      "2019-11-16 15:33:53,378 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=134413794\n",
      "\t\tFILE: Number of bytes written=14435230\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318582\n",
      "\t\tMap output records=318582\n",
      "\t\tMap output bytes=2797072\n",
      "\t\tMap output materialized bytes=3434242\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318582\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=212\n",
      "\t\tTotal committed heap usage (bytes)=188219392\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:33:53,380 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000003_0\n",
      "2019-11-16 15:33:53,380 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000004_0\n",
      "2019-11-16 15:33:53,398 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:33:53,398 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:33:53,398 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:33:53,413 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:134217728+33554432\n",
      "2019-11-16 15:33:53,432 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:33:53,496 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:33:53,496 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:33:53,496 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:33:53,497 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:33:53,497 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:33:53,515 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:33:53,575 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:33:53,665 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:53,665 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:53,668 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:53,677 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:53,717 INFO streaming.PipeMapRed: Records R/W=2511/1\n",
      "2019-11-16 15:33:53,854 INFO streaming.PipeMapRed: R/W/S=10000/6033/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:33:55,963 INFO streaming.PipeMapRed: R/W/S=100000/90525/0 in:50000=100000/2 [rec/s] out:45262=90525/2 [rec/s]\n",
      "2019-11-16 15:33:58,049 INFO streaming.PipeMapRed: R/W/S=200000/190653/0 in:50000=200000/4 [rec/s] out:47663=190653/4 [rec/s]\n",
      "2019-11-16 15:33:59,437 INFO mapred.LocalJobRunner: Records R/W=2511/1 > map\n",
      "2019-11-16 15:33:59,855 INFO mapreduce.Job:  map 65% reduce 0%\n",
      "2019-11-16 15:34:00,217 INFO streaming.PipeMapRed: R/W/S=300000/291075/0 in:50000=300000/6 [rec/s] out:48512=291075/6 [rec/s]\n",
      "2019-11-16 15:34:00,867 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:34:00,968 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:34:00,969 INFO mapred.LocalJobRunner: Records R/W=2511/1 > map\n",
      "2019-11-16 15:34:00,971 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:34:00,971 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:34:00,971 INFO mapred.MapTask: bufstart = 0; bufend = 2797197; bufvoid = 104857600\n",
      "2019-11-16 15:34:00,971 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940040(99760160); length = 1274357/6553600\n",
      "2019-11-16 15:34:01,421 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:34:01,459 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000004_0 is done. And is in the process of committing\n",
      "2019-11-16 15:34:01,499 INFO mapred.LocalJobRunner: Records R/W=2511/1\n",
      "2019-11-16 15:34:01,504 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000004_0' done.\n",
      "2019-11-16 15:34:01,511 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=167973059\n",
      "\t\tFILE: Number of bytes written=17869645\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318590\n",
      "\t\tMap output records=318590\n",
      "\t\tMap output bytes=2797197\n",
      "\t\tMap output materialized bytes=3434383\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318590\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=319291392\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:34:01,524 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000004_0\n",
      "2019-11-16 15:34:01,534 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000005_0\n",
      "2019-11-16 15:34:01,577 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:34:01,578 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:34:01,580 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:34:01,636 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:167772160+33554432\n",
      "2019-11-16 15:34:01,714 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:34:01,807 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:34:01,807 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:34:01,807 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:34:01,807 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:34:01,807 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:34:01,809 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:34:01,831 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:34:01,881 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:34:01,933 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:01,936 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:01,938 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:01,942 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:02,185 INFO streaming.PipeMapRed: Records R/W=2532/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:34:02,273 INFO streaming.PipeMapRed: R/W/S=10000/2992/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:04,792 INFO streaming.PipeMapRed: R/W/S=100000/88898/0 in:50000=100000/2 [rec/s] out:44449=88899/2 [rec/s]\n",
      "2019-11-16 15:34:08,025 INFO streaming.PipeMapRed: R/W/S=200000/190583/0 in:33333=200000/6 [rec/s] out:31763=190583/6 [rec/s]\n",
      "2019-11-16 15:34:11,575 INFO streaming.PipeMapRed: R/W/S=300000/292019/0 in:33333=300000/9 [rec/s] out:32446=292019/9 [rec/s]\n",
      "2019-11-16 15:34:12,102 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:34:12,180 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:34:12,183 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:34:12,183 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:34:12,184 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:34:12,184 INFO mapred.MapTask: bufstart = 0; bufend = 2798536; bufvoid = 104857600\n",
      "2019-11-16 15:34:12,184 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940136(99760544); length = 1274261/6553600\n",
      "2019-11-16 15:34:12,852 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:34:12,875 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000005_0 is done. And is in the process of committing\n",
      "2019-11-16 15:34:12,882 INFO mapred.LocalJobRunner: Records R/W=2532/1\n",
      "2019-11-16 15:34:12,889 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000005_0' done.\n",
      "2019-11-16 15:34:12,890 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=201531812\n",
      "\t\tFILE: Number of bytes written=21305351\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318566\n",
      "\t\tMap output records=318566\n",
      "\t\tMap output bytes=2798536\n",
      "\t\tMap output materialized bytes=3435674\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318566\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=421527552\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:34:12,893 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000005_0\n",
      "2019-11-16 15:34:12,898 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_m_000006_0\n",
      "2019-11-16 15:34:12,939 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:34:12,939 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:34:12,940 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:34:12,972 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:201326592+4161225\n",
      "2019-11-16 15:34:13,139 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:34:13,794 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:34:13,797 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:34:13,799 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:34:13,801 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:34:13,802 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:34:13,812 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:34:14,039 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_mapper.py]\n",
      "2019-11-16 15:34:14,128 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:14,129 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:14,131 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:14,135 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:14,570 INFO streaming.PipeMapRed: Records R/W=2492/1\n",
      "2019-11-16 15:34:14,729 INFO streaming.PipeMapRed: R/W/S=10000/3665/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:15,634 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:34:15,856 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:34:15,857 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:34:15,857 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:34:15,858 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:34:15,859 INFO mapred.MapTask: bufstart = 0; bufend = 346634; bufvoid = 104857600\n",
      "2019-11-16 15:34:15,859 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26056448(104225792); length = 157949/6553600\n",
      "2019-11-16 15:34:15,902 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:34:15,910 INFO mapreduce.Job:  map 86% reduce 0%\n",
      "2019-11-16 15:34:15,924 INFO mapred.Task: Task:attempt_local1890731080_0001_m_000006_0 is done. And is in the process of committing\n",
      "2019-11-16 15:34:15,932 INFO mapred.LocalJobRunner: Records R/W=2492/1\n",
      "2019-11-16 15:34:15,932 INFO mapred.Task: Task 'attempt_local1890731080_0001_m_000006_0' done.\n",
      "2019-11-16 15:34:15,934 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=205693262\n",
      "\t\tFILE: Number of bytes written=21730999\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=39488\n",
      "\t\tMap output records=39488\n",
      "\t\tMap output bytes=346634\n",
      "\t\tMap output materialized bytes=425616\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=39488\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=444\n",
      "\t\tTotal committed heap usage (bytes)=245891072\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4161225\n",
      "2019-11-16 15:34:15,936 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_m_000006_0\n",
      "2019-11-16 15:34:15,937 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2019-11-16 15:34:15,959 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2019-11-16 15:34:15,961 INFO mapred.LocalJobRunner: Starting task: attempt_local1890731080_0001_r_000000_0\n",
      "2019-11-16 15:34:16,064 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:34:16,064 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:34:16,065 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:34:16,089 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28c7d44e\n",
      "2019-11-16 15:34:16,100 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-16 15:34:16,255 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-16 15:34:16,309 INFO reduce.EventFetcher: attempt_local1890731080_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-16 15:34:16,446 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000003_0 decomp: 3434238 len: 3434242 to MEMORY\n",
      "2019-11-16 15:34:16,497 INFO reduce.InMemoryMapOutput: Read 3434238 bytes from map-output for attempt_local1890731080_0001_m_000003_0\n",
      "2019-11-16 15:34:16,516 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3434238, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3434238\n",
      "2019-11-16 15:34:16,533 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000006_0 decomp: 425612 len: 425616 to MEMORY\n",
      "2019-11-16 15:34:16,554 INFO reduce.InMemoryMapOutput: Read 425612 bytes from map-output for attempt_local1890731080_0001_m_000006_0\n",
      "2019-11-16 15:34:16,554 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 425612, inMemoryMapOutputs.size() -> 2, commitMemory -> 3434238, usedMemory ->3859850\n",
      "2019-11-16 15:34:16,559 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000000_0 decomp: 3436163 len: 3436167 to MEMORY\n",
      "2019-11-16 15:34:16,575 INFO reduce.InMemoryMapOutput: Read 3436163 bytes from map-output for attempt_local1890731080_0001_m_000000_0\n",
      "2019-11-16 15:34:16,584 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3436163, inMemoryMapOutputs.size() -> 3, commitMemory -> 3859850, usedMemory ->7296013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:34:16,622 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000001_0 decomp: 3434548 len: 3434552 to MEMORY\n",
      "2019-11-16 15:34:16,672 INFO reduce.InMemoryMapOutput: Read 3434548 bytes from map-output for attempt_local1890731080_0001_m_000001_0\n",
      "2019-11-16 15:34:16,677 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3434548, inMemoryMapOutputs.size() -> 4, commitMemory -> 7296013, usedMemory ->10730561\n",
      "2019-11-16 15:34:16,715 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000004_0 decomp: 3434379 len: 3434383 to MEMORY\n",
      "2019-11-16 15:34:16,802 INFO reduce.InMemoryMapOutput: Read 3434379 bytes from map-output for attempt_local1890731080_0001_m_000004_0\n",
      "2019-11-16 15:34:16,802 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3434379, inMemoryMapOutputs.size() -> 5, commitMemory -> 10730561, usedMemory ->14164940\n",
      "2019-11-16 15:34:16,806 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000002_0 decomp: 3434287 len: 3434291 to MEMORY\n",
      "2019-11-16 15:34:16,822 INFO reduce.InMemoryMapOutput: Read 3434287 bytes from map-output for attempt_local1890731080_0001_m_000002_0\n",
      "2019-11-16 15:34:16,823 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3434287, inMemoryMapOutputs.size() -> 6, commitMemory -> 14164940, usedMemory ->17599227\n",
      "2019-11-16 15:34:16,833 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890731080_0001_m_000005_0 decomp: 3435670 len: 3435674 to MEMORY\n",
      "2019-11-16 15:34:16,845 INFO reduce.InMemoryMapOutput: Read 3435670 bytes from map-output for attempt_local1890731080_0001_m_000005_0\n",
      "2019-11-16 15:34:16,846 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3435670, inMemoryMapOutputs.size() -> 7, commitMemory -> 17599227, usedMemory ->21034897\n",
      "2019-11-16 15:34:16,847 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-16 15:34:16,849 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "2019-11-16 15:34:16,850 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-16 15:34:16,880 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:34:16,900 INFO mapred.Merger: Merging 7 sorted segments\n",
      "2019-11-16 15:34:16,915 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 21034834 bytes\n",
      "2019-11-16 15:34:19,326 INFO reduce.MergeManagerImpl: Merged 7 segments, 21034897 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-16 15:34:19,327 INFO reduce.MergeManagerImpl: Merging 1 files, 21034889 bytes from disk\n",
      "2019-11-16 15:34:19,330 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-16 15:34:19,333 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-16 15:34:19,339 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21034876 bytes\n",
      "2019-11-16 15:34:19,344 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "2019-11-16 15:34:19,441 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex1_reducer.py]\n",
      "2019-11-16 15:34:19,446 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2019-11-16 15:34:19,447 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2019-11-16 15:34:19,614 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:19,617 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:19,624 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:19,664 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:19,755 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:20,122 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:20,457 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:34:21,140 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:300000=300000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "2019-11-16 15:34:21,947 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:200000=400000/2 [rec/s] out:0=0/2 [rec/s]\n",
      "2019-11-16 15:34:22,766 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:166666=500000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "2019-11-16 15:34:23,083 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:200000=600000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "2019-11-16 15:34:23,226 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:233333=700000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "2019-11-16 15:34:23,349 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:266666=800000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "2019-11-16 15:34:23,651 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:225000=900000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:23,796 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:250000=1000000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:23,934 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:275000=1100000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:24,081 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:300000=1200000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:24,208 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:325000=1300000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:24,411 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:350000=1400000/4 [rec/s] out:0=0/4 [rec/s]\n",
      "2019-11-16 15:34:24,710 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:300000=1500000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "2019-11-16 15:34:24,962 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:320000=1600000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "2019-11-16 15:34:25,092 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:340000=1700000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "2019-11-16 15:34:25,229 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:360000=1800000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "2019-11-16 15:34:25,365 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:380000=1900000/5 [rec/s] out:0=0/5 [rec/s]\n",
      "2019-11-16 15:34:25,442 INFO streaming.PipeMapRed: Records R/W=1951229/1\n",
      "2019-11-16 15:34:25,447 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:34:25,449 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:34:25,455 INFO mapred.Task: Task:attempt_local1890731080_0001_r_000000_0 is done. And is in the process of committing\n",
      "2019-11-16 15:34:25,467 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "2019-11-16 15:34:25,467 INFO mapred.Task: Task attempt_local1890731080_0001_r_000000_0 is allowed to commit now\n",
      "2019-11-16 15:34:25,580 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1890731080_0001_r_000000_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex1-MapRed\n",
      "2019-11-16 15:34:25,581 INFO mapred.LocalJobRunner: Records R/W=1951229/1 > reduce\n",
      "2019-11-16 15:34:25,582 INFO mapred.Task: Task 'attempt_local1890731080_0001_r_000000_0' done.\n",
      "2019-11-16 15:34:25,590 INFO mapred.Task: Final Counters for attempt_local1890731080_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=247763300\n",
      "\t\tFILE: Number of bytes written=42765971\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=21034925\n",
      "\t\tReduce input records=1951229\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=1951229\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=282591232\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=83\n",
      "2019-11-16 15:34:25,591 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890731080_0001_r_000000_0\n",
      "2019-11-16 15:34:25,592 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2019-11-16 15:34:25,898 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2019-11-16 15:34:25,898 INFO mapreduce.Job: Job job_local1890731080_0001 completed successfully\n",
      "2019-11-16 15:34:25,968 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1159261019\n",
      "\t\tFILE: Number of bytes written=140806834\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1951229\n",
      "\t\tMap output records=1951229\n",
      "\t\tMap output bytes=17132425\n",
      "\t\tMap output materialized bytes=21034925\n",
      "\t\tInput split bytes=714\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=21034925\n",
      "\t\tReduce input records=1951229\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=3902458\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=688\n",
      "\t\tTotal committed heap usage (bytes)=2296381440\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=205512393\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=83\n",
      "2019-11-16 15:34:25,969 INFO streaming.StreamJob: Output directory: results/Ex1-MapRed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.47 s, sys: 1.45 s, total: 3.92 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! chmod a+x {mapper_path_ex1} && chmod a+x {reducer_path_ex1}\n",
    "! rm -rf {results_ex1_mapred_path}\n",
    "! hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -mapper {mapper_path_ex1} -reducer {reducer_path_ex1} -input {data_big_path} -output {results_ex1_mapred_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU times: **user** 1.5 s, **sys**: 770 ms, **total**: 2.27 s <br>\n",
    "Wall time: 45.4 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa\t576686\r\n",
      "Americas\t626963\r\n",
      "Asia\t1191797\r\n",
      "Europe\t362135\r\n",
      "Oceania\t89256\r\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "! cat {results_ex1_mapred_path}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Create an inverted index with the following structure:\n",
    "- disaster_type : regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex2_mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%file {mapper_path_ex2}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split(\",\")\n",
    "    dis_type = words[3]\n",
    "    region = words[6]\n",
    "    print(f\"('{dis_type}','{region}')\\t1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex2_reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%file {reducer_path_ex2}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "\n",
    "curr_region = ''\n",
    "is_first_dist_type = True\n",
    "curr_dist_type = ''\n",
    "regions = []\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # separate compositeKey,value\n",
    "    key,_ = line.split('\\t')\n",
    "    # remove  leading '(' and trailing ')'\n",
    "    key = key[1:-1]\n",
    "    # separate compositeKey\n",
    "    dis_type,region = key.split(',')\n",
    "    \n",
    "    if is_first_dist_type:\n",
    "        is_first_dist_type = False\n",
    "        curr_dist_type = dis_type\n",
    "        regions = [region]\n",
    "        curr_region = region\n",
    "        continue\n",
    "        \n",
    "    if dis_type != curr_dist_type:\n",
    "        print(curr_dist_type+\"\\t\"+str(regions))\n",
    "        regions = [region]\n",
    "        curr_region = region\n",
    "        curr_dist_type = dis_type\n",
    "        continue\n",
    "        \n",
    "    if region != curr_region:\n",
    "        regions.append(region)\n",
    "        curr_region = region\n",
    "\n",
    "print(curr_dist_type+\"\\t\"+str(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: $HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar [options]\n",
      "Options:\n",
      "  -input          <path> DFS input file(s) for the Map step.\n",
      "  -output         <path> DFS output directory for the Reduce step.\n",
      "  -mapper         <cmd|JavaClassName> Optional. Command to be run as mapper.\n",
      "  -combiner       <cmd|JavaClassName> Optional. Command to be run as combiner.\n",
      "  -reducer        <cmd|JavaClassName> Optional. Command to be run as reducer.\n",
      "  -file           <file> Optional. File/dir to be shipped in the Job jar file.\n",
      "                  Deprecated. Use generic option \"-files\" instead.\n",
      "  -inputformat    <TextInputFormat(default)|SequenceFileAsTextInputFormat|JavaClassName>\n",
      "                  Optional. The input format class.\n",
      "  -outputformat   <TextOutputFormat(default)|JavaClassName>\n",
      "                  Optional. The output format class.\n",
      "  -partitioner    <JavaClassName>  Optional. The partitioner class.\n",
      "  -numReduceTasks <num> Optional. Number of reduce tasks.\n",
      "  -inputreader    <spec> Optional. Input recordreader spec.\n",
      "  -cmdenv         <n>=<v> Optional. Pass env.var to streaming commands.\n",
      "  -mapdebug       <cmd> Optional. To run this script when a map task fails.\n",
      "  -reducedebug    <cmd> Optional. To run this script when a reduce task fails.\n",
      "  -io             <identifier> Optional. Format to use for input to and output\n",
      "                  from mapper/reducer commands\n",
      "  -lazyOutput     Optional. Lazily create Output.\n",
      "  -background     Optional. Submit the job and don't wait till it completes.\n",
      "  -verbose        Optional. Print verbose output.\n",
      "  -info           Optional. Print detailed usage.\n",
      "  -help           Optional. Print help message.\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n",
      "\n",
      "Usage tips:\n",
      "In -input: globbing on <path> is supported and can have multiple -input\n",
      "\n",
      "Default Map input format: a line is a record in UTF-8 the key part ends at first\n",
      "  TAB, the rest of the line is the value\n",
      "\n",
      "To pass a Custom input format:\n",
      "  -inputformat package.MyInputFormat\n",
      "\n",
      "Similarly, to pass a custom output format:\n",
      "  -outputformat package.MyOutputFormat\n",
      "\n",
      "The files with extensions .class and .jar/.zip, specified for the -file\n",
      "  argument[s], end up in \"classes\" and \"lib\" directories respectively inside\n",
      "  the working directory when the mapper and reducer are run. All other files\n",
      "  specified for the -file argument[s] end up in the working directory when the\n",
      "  mapper and reducer are run. The location of this working directory is\n",
      "  unspecified.\n",
      "\n",
      "To set the number of reduce tasks (num. of output files) as, say 10:\n",
      "  Use -numReduceTasks 10\n",
      "To skip the sort/combine/shuffle/sort/reduce step:\n",
      "  Use -numReduceTasks 0\n",
      "  Map output then becomes a 'side-effect output' rather than a reduce input.\n",
      "  This speeds up processing. This also feels more like \"in-place\" processing\n",
      "  because the input filename and the map input order are preserved.\n",
      "  This is equivalent to -reducer NONE\n",
      "\n",
      "To speed up the last maps:\n",
      "  -D mapreduce.map.speculative=true\n",
      "To speed up the last reduces:\n",
      "  -D mapreduce.reduce.speculative=true\n",
      "To name the job (appears in the JobTracker Web UI):\n",
      "  -D mapreduce.job.name='My Job'\n",
      "To change the local temp directory:\n",
      "  -D dfs.data.dir=/tmp/dfs\n",
      "  -D stream.tmpdir=/tmp/streaming\n",
      "Additional local temp directories with -jt local:\n",
      "  -D mapreduce.cluster.local.dir=/tmp/local\n",
      "  -D mapreduce.jobtracker.system.dir=/tmp/system\n",
      "  -D mapreduce.cluster.temp.dir=/tmp/temp\n",
      "To treat tasks with non-zero exit status as SUCCEDED:\n",
      "  -D stream.non.zero.exit.is.failure=false\n",
      "Use a custom hadoop streaming build along with standard hadoop install:\n",
      "  $HADOOP_HOME/bin/hadoop jar /path/my-hadoop-streaming.jar [...]\\\n",
      "    [...] -D stream.shipped.hadoopstreaming=/path/my-hadoop-streaming.jar\n",
      "For more details about jobconf parameters see:\n",
      "  http://wiki.apache.org/hadoop/JobConfFile\n",
      "Truncate the values of the job configuration copiedto the environment at the given length:\n",
      "   -D stream.jobconf.truncate.limit=-1\n",
      "To set an environment variable in a streaming command:\n",
      "   -cmdenv EXAMPLE_DIR=/home/example/dictionaries/\n",
      "\n",
      "Shortcut:\n",
      "   setenv HSTREAMING \"$HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar\"\n",
      "\n",
      "Example: $HSTREAMING -mapper \"/usr/local/bin/perl5 filter.pl\"\n",
      "           -file /local/filter.pl -input \"/logs/0604*/*\" [...]\n",
      "  Ships a script, invokes the non-shipped perl interpreter. Shipped files go to\n",
      "  the working directory so filter.pl is found by perl. Input files are all the\n",
      "  daily logs for days in month 2006-04\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-17 10:54:45,124 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2019-11-17 10:54:45,398 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2019-11-17 10:54:45,399 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2019-11-17 10:54:45,428 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:45,781 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2019-11-17 10:54:45,807 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2019-11-17 10:54:46,128 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local17561207_0001\n",
      "2019-11-17 10:54:46,129 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2019-11-17 10:54:46,365 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2019-11-17 10:54:46,368 INFO mapreduce.Job: Running job: job_local17561207_0001\n",
      "2019-11-17 10:54:46,385 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2019-11-17 10:54:46,391 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2019-11-17 10:54:46,399 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:46,399 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:46,496 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2019-11-17 10:54:46,501 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:46,701 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:46,704 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:46,771 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:46,788 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_small.csv:0+1725939\n",
      "2019-11-17 10:54:46,842 INFO mapred.MapTask: numReduceTasks: 5\n",
      "2019-11-17 10:54:46,935 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-17 10:54:46,935 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-17 10:54:46,935 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-17 10:54:46,935 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-17 10:54:46,935 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-17 10:54:46,940 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-17 10:54:46,958 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_mapper.py]\n",
      "2019-11-17 10:54:46,974 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2019-11-17 10:54:46,975 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2019-11-17 10:54:46,976 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2019-11-17 10:54:46,976 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2019-11-17 10:54:46,977 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2019-11-17 10:54:46,978 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2019-11-17 10:54:46,978 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2019-11-17 10:54:46,979 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2019-11-17 10:54:46,979 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2019-11-17 10:54:46,980 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2019-11-17 10:54:46,981 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2019-11-17 10:54:46,981 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2019-11-17 10:54:47,112 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:47,113 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:47,125 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:47,155 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:47,272 INFO streaming.PipeMapRed: Records R/W=1276/1\n",
      "2019-11-17 10:54:47,387 INFO mapreduce.Job: Job job_local17561207_0001 running in uber mode : false\n",
      "2019-11-17 10:54:47,389 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2019-11-17 10:54:47,583 INFO streaming.PipeMapRed: R/W/S=10000/6320/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:47,743 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:47,745 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:47,753 INFO mapred.LocalJobRunner: \n",
      "2019-11-17 10:54:47,755 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-17 10:54:47,755 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-17 10:54:47,755 INFO mapred.MapTask: bufstart = 0; bufend = 575752; bufvoid = 104857600\n",
      "2019-11-17 10:54:47,755 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26149308(104597232); length = 65089/6553600\n",
      "2019-11-17 10:54:47,916 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-17 10:54:47,964 INFO mapred.Task: Task:attempt_local17561207_0001_m_000000_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:48,004 INFO mapred.LocalJobRunner: Records R/W=1276/1\n",
      "2019-11-17 10:54:48,004 INFO mapred.Task: Task 'attempt_local17561207_0001_m_000000_0' done.\n",
      "2019-11-17 10:54:48,029 INFO mapred.Task: Final Counters for attempt_local17561207_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1902685\n",
      "\t\tFILE: Number of bytes written=1298571\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16273\n",
      "\t\tMap output records=16273\n",
      "\t\tMap output bytes=575752\n",
      "\t\tMap output materialized bytes=608328\n",
      "\t\tInput split bytes=104\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16273\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1725939\n",
      "2019-11-17 10:54:48,033 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:48,038 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2019-11-17 10:54:48,060 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2019-11-17 10:54:48,077 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_r_000000_0\n",
      "2019-11-17 10:54:48,181 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:48,182 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:48,183 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:48,192 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@621ea382\n",
      "2019-11-17 10:54:48,208 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:48,270 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-17 10:54:48,277 INFO reduce.EventFetcher: attempt_local17561207_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-17 10:54:48,395 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-17 10:54:48,404 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local17561207_0001_m_000000_0 decomp: 116428 len: 116432 to MEMORY\n",
      "2019-11-17 10:54:48,412 INFO reduce.InMemoryMapOutput: Read 116428 bytes from map-output for attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:48,425 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 116428, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->116428\n",
      "2019-11-17 10:54:48,430 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-17 10:54:48,434 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:48,434 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-17 10:54:48,442 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:48,442 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116386 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-17 10:54:48,479 INFO reduce.MergeManagerImpl: Merged 1 segments, 116428 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-17 10:54:48,481 INFO reduce.MergeManagerImpl: Merging 1 files, 116432 bytes from disk\n",
      "2019-11-17 10:54:48,488 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-17 10:54:48,489 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:48,490 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 116386 bytes\n",
      "2019-11-17 10:54:48,491 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:48,524 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_reducer.py]\n",
      "2019-11-17 10:54:48,561 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2019-11-17 10:54:48,564 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2019-11-17 10:54:48,691 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:48,692 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:48,697 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:48,724 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:48,847 INFO streaming.PipeMapRed: Records R/W=3032/1\n",
      "2019-11-17 10:54:48,854 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:48,888 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:49,078 INFO mapred.Task: Task:attempt_local17561207_0001_r_000000_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:49,135 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:49,137 INFO mapred.Task: Task attempt_local17561207_0001_r_000000_0 is allowed to commit now\n",
      "2019-11-17 10:54:49,218 INFO output.FileOutputCommitter: Saved output of task 'attempt_local17561207_0001_r_000000_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex2-MapRed\n",
      "2019-11-17 10:54:49,220 INFO mapred.LocalJobRunner: Records R/W=3032/1 > reduce\n",
      "2019-11-17 10:54:49,221 INFO mapred.Task: Task 'attempt_local17561207_0001_r_000000_0' done.\n",
      "2019-11-17 10:54:49,222 INFO mapred.Task: Final Counters for attempt_local17561207_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2139769\n",
      "\t\tFILE: Number of bytes written=1416620\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=66\n",
      "\t\tReduce shuffle bytes=116432\n",
      "\t\tReduce input records=3032\n",
      "\t\tReduce output records=15\n",
      "\t\tSpilled Records=3032\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1617\n",
      "2019-11-17 10:54:49,223 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_r_000000_0\n",
      "2019-11-17 10:54:49,223 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_r_000001_0\n",
      "2019-11-17 10:54:49,228 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:49,228 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:49,229 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:49,229 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32ab0681\n",
      "2019-11-17 10:54:49,230 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:49,259 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-17 10:54:49,268 INFO reduce.EventFetcher: attempt_local17561207_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-17 10:54:49,275 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local17561207_0001_m_000000_0 decomp: 75139 len: 75143 to MEMORY\n",
      "2019-11-17 10:54:49,285 INFO reduce.InMemoryMapOutput: Read 75139 bytes from map-output for attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:49,289 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 75139, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->75139\n",
      "2019-11-17 10:54:49,292 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-17 10:54:49,295 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:49,308 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-17 10:54:49,316 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:49,318 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75094 bytes\n",
      "2019-11-17 10:54:49,327 INFO reduce.MergeManagerImpl: Merged 1 segments, 75139 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-17 10:54:49,328 INFO reduce.MergeManagerImpl: Merging 1 files, 75143 bytes from disk\n",
      "2019-11-17 10:54:49,329 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-17 10:54:49,329 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:49,330 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 75094 bytes\n",
      "2019-11-17 10:54:49,331 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:49,355 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_reducer.py]\n",
      "2019-11-17 10:54:49,402 INFO mapreduce.Job:  map 100% reduce 20%\n",
      "2019-11-17 10:54:49,507 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:49,507 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:49,508 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:49,518 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:49,619 INFO streaming.PipeMapRed: Records R/W=1982/1\n",
      "2019-11-17 10:54:49,636 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:49,636 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:49,639 INFO mapred.Task: Task:attempt_local17561207_0001_r_000001_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:49,650 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:49,651 INFO mapred.Task: Task attempt_local17561207_0001_r_000001_0 is allowed to commit now\n",
      "2019-11-17 10:54:49,759 INFO output.FileOutputCommitter: Saved output of task 'attempt_local17561207_0001_r_000001_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex2-MapRed\n",
      "2019-11-17 10:54:49,766 INFO mapred.LocalJobRunner: Records R/W=1982/1 > reduce\n",
      "2019-11-17 10:54:49,766 INFO mapred.Task: Task 'attempt_local17561207_0001_r_000001_0' done.\n",
      "2019-11-17 10:54:49,768 INFO mapred.Task: Final Counters for attempt_local17561207_0001_r_000001_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2294275\n",
      "\t\tFILE: Number of bytes written=1493008\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=50\n",
      "\t\tReduce shuffle bytes=75143\n",
      "\t\tReduce input records=1982\n",
      "\t\tReduce output records=14\n",
      "\t\tSpilled Records=1982\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1245\n",
      "2019-11-17 10:54:49,774 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_r_000001_0\n",
      "2019-11-17 10:54:49,776 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_r_000002_0\n",
      "2019-11-17 10:54:49,787 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:49,788 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:49,789 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:49,789 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@501a6ab2\n",
      "2019-11-17 10:54:49,790 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:49,796 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-17 10:54:49,801 INFO reduce.EventFetcher: attempt_local17561207_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-17 10:54:49,807 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local17561207_0001_m_000000_0 decomp: 115357 len: 115361 to MEMORY\n",
      "2019-11-17 10:54:49,810 INFO reduce.InMemoryMapOutput: Read 115357 bytes from map-output for attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:49,816 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 115357, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->115357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-17 10:54:49,821 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-17 10:54:49,843 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:49,845 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-17 10:54:49,867 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:49,867 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 115318 bytes\n",
      "2019-11-17 10:54:49,896 INFO reduce.MergeManagerImpl: Merged 1 segments, 115357 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-17 10:54:49,899 INFO reduce.MergeManagerImpl: Merging 1 files, 115361 bytes from disk\n",
      "2019-11-17 10:54:49,901 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-17 10:54:49,902 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:49,904 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 115318 bytes\n",
      "2019-11-17 10:54:49,907 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:50,034 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_reducer.py]\n",
      "2019-11-17 10:54:50,201 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,201 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,206 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,214 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,357 INFO streaming.PipeMapRed: Records R/W=3083/1\n",
      "2019-11-17 10:54:50,357 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:50,362 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:50,369 INFO mapred.Task: Task:attempt_local17561207_0001_r_000002_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:50,377 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:50,377 INFO mapred.Task: Task attempt_local17561207_0001_r_000002_0 is allowed to commit now\n",
      "2019-11-17 10:54:50,439 INFO mapreduce.Job:  map 100% reduce 40%\n",
      "2019-11-17 10:54:50,489 INFO output.FileOutputCommitter: Saved output of task 'attempt_local17561207_0001_r_000002_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex2-MapRed\n",
      "2019-11-17 10:54:50,491 INFO mapred.LocalJobRunner: Records R/W=3083/1 > reduce\n",
      "2019-11-17 10:54:50,491 INFO mapred.Task: Task 'attempt_local17561207_0001_r_000002_0' done.\n",
      "2019-11-17 10:54:50,491 INFO mapred.Task: Final Counters for attempt_local17561207_0001_r_000002_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2529217\n",
      "\t\tFILE: Number of bytes written=1609777\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=56\n",
      "\t\tReduce shuffle bytes=115361\n",
      "\t\tReduce input records=3083\n",
      "\t\tReduce output records=15\n",
      "\t\tSpilled Records=3083\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=35\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1408\n",
      "2019-11-17 10:54:50,492 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_r_000002_0\n",
      "2019-11-17 10:54:50,492 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_r_000003_0\n",
      "2019-11-17 10:54:50,500 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:50,500 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:50,501 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:50,502 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7bd874a7\n",
      "2019-11-17 10:54:50,505 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:50,566 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-17 10:54:50,584 INFO reduce.EventFetcher: attempt_local17561207_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-17 10:54:50,594 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local17561207_0001_m_000000_0 decomp: 136447 len: 136451 to MEMORY\n",
      "2019-11-17 10:54:50,595 INFO reduce.InMemoryMapOutput: Read 136447 bytes from map-output for attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:50,598 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 136447, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->136447\n",
      "2019-11-17 10:54:50,600 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-17 10:54:50,602 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:50,603 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-17 10:54:50,605 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:50,606 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 136405 bytes\n",
      "2019-11-17 10:54:50,618 INFO reduce.MergeManagerImpl: Merged 1 segments, 136447 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-17 10:54:50,620 INFO reduce.MergeManagerImpl: Merging 1 files, 136451 bytes from disk\n",
      "2019-11-17 10:54:50,620 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-17 10:54:50,620 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:50,622 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 136405 bytes\n",
      "2019-11-17 10:54:50,623 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:50,641 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_reducer.py]\n",
      "2019-11-17 10:54:50,832 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,832 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,833 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,836 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:50,969 INFO streaming.PipeMapRed: Records R/W=3811/1\n",
      "2019-11-17 10:54:50,976 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:50,977 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:50,987 INFO mapred.Task: Task:attempt_local17561207_0001_r_000003_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:51,000 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:51,001 INFO mapred.Task: Task attempt_local17561207_0001_r_000003_0 is allowed to commit now\n",
      "2019-11-17 10:54:51,096 INFO output.FileOutputCommitter: Saved output of task 'attempt_local17561207_0001_r_000003_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex2-MapRed\n",
      "2019-11-17 10:54:51,106 INFO mapred.LocalJobRunner: Records R/W=3811/1 > reduce\n",
      "2019-11-17 10:54:51,107 INFO mapred.Task: Task 'attempt_local17561207_0001_r_000003_0' done.\n",
      "2019-11-17 10:54:51,109 INFO mapred.Task: Final Counters for attempt_local17561207_0001_r_000003_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2806339\n",
      "\t\tFILE: Number of bytes written=1747879\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=69\n",
      "\t\tReduce shuffle bytes=136451\n",
      "\t\tReduce input records=3811\n",
      "\t\tReduce output records=15\n",
      "\t\tSpilled Records=3811\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1651\n",
      "2019-11-17 10:54:51,109 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_r_000003_0\n",
      "2019-11-17 10:54:51,109 INFO mapred.LocalJobRunner: Starting task: attempt_local17561207_0001_r_000004_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-17 10:54:51,127 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-17 10:54:51,127 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-17 10:54:51,140 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-17 10:54:51,141 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@374e2496\n",
      "2019-11-17 10:54:51,141 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-17 10:54:51,144 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-17 10:54:51,147 INFO reduce.EventFetcher: attempt_local17561207_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-17 10:54:51,155 INFO reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local17561207_0001_m_000000_0 decomp: 164937 len: 164941 to MEMORY\n",
      "2019-11-17 10:54:51,158 INFO reduce.InMemoryMapOutput: Read 164937 bytes from map-output for attempt_local17561207_0001_m_000000_0\n",
      "2019-11-17 10:54:51,158 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 164937, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->164937\n",
      "2019-11-17 10:54:51,160 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-17 10:54:51,162 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:51,163 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-17 10:54:51,169 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:51,169 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 164898 bytes\n",
      "2019-11-17 10:54:51,185 INFO reduce.MergeManagerImpl: Merged 1 segments, 164937 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-17 10:54:51,186 INFO reduce.MergeManagerImpl: Merging 1 files, 164941 bytes from disk\n",
      "2019-11-17 10:54:51,187 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-17 10:54:51,187 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-17 10:54:51,189 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 164898 bytes\n",
      "2019-11-17 10:54:51,192 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:51,289 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex2_reducer.py]\n",
      "2019-11-17 10:54:51,440 INFO mapreduce.Job:  map 100% reduce 80%\n",
      "2019-11-17 10:54:51,456 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:51,456 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:51,457 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:51,460 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-17 10:54:51,584 INFO streaming.PipeMapRed: Records R/W=4365/1\n",
      "2019-11-17 10:54:51,594 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-17 10:54:51,598 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-17 10:54:51,602 INFO mapred.Task: Task:attempt_local17561207_0001_r_000004_0 is done. And is in the process of committing\n",
      "2019-11-17 10:54:51,622 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2019-11-17 10:54:51,622 INFO mapred.Task: Task attempt_local17561207_0001_r_000004_0 is allowed to commit now\n",
      "2019-11-17 10:54:51,755 INFO output.FileOutputCommitter: Saved output of task 'attempt_local17561207_0001_r_000004_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex2-MapRed\n",
      "2019-11-17 10:54:51,758 INFO mapred.LocalJobRunner: Records R/W=4365/1 > reduce\n",
      "2019-11-17 10:54:51,758 INFO mapred.Task: Task 'attempt_local17561207_0001_r_000004_0' done.\n",
      "2019-11-17 10:54:51,768 INFO mapred.Task: Final Counters for attempt_local17561207_0001_r_000004_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3136349\n",
      "\t\tFILE: Number of bytes written=1914311\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=58\n",
      "\t\tReduce shuffle bytes=164941\n",
      "\t\tReduce input records=4365\n",
      "\t\tReduce output records=17\n",
      "\t\tSpilled Records=4365\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=203948032\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1491\n",
      "2019-11-17 10:54:51,769 INFO mapred.LocalJobRunner: Finishing task: attempt_local17561207_0001_r_000004_0\n",
      "2019-11-17 10:54:51,771 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2019-11-17 10:54:52,442 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2019-11-17 10:54:52,443 INFO mapreduce.Job: Job job_local17561207_0001 completed successfully\n",
      "2019-11-17 10:54:52,516 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14808634\n",
      "\t\tFILE: Number of bytes written=9480166\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16273\n",
      "\t\tMap output records=16273\n",
      "\t\tMap output bytes=575752\n",
      "\t\tMap output materialized bytes=608328\n",
      "\t\tInput split bytes=104\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=299\n",
      "\t\tReduce shuffle bytes=608328\n",
      "\t\tReduce input records=16273\n",
      "\t\tReduce output records=76\n",
      "\t\tSpilled Records=32546\n",
      "\t\tShuffled Maps =5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=5\n",
      "\t\tGC time elapsed (ms)=35\n",
      "\t\tTotal committed heap usage (bytes)=1223688192\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1725939\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=7412\n",
      "2019-11-17 10:54:52,519 INFO streaming.StreamJob: Output directory: results/Ex2-MapRed\n",
      "CPU times: user 570 ms, sys: 210 ms, total: 780 ms\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! chmod a+x {mapper_path_ex2} && chmod a+x {reducer_path_ex2}\n",
    "! rm -rf {results_ex2_mapred_path}\n",
    "! hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -Dmapreduce.job.maps=5 -Dmapreduce.job.reduces=5 -mapper {mapper_path_ex2} -reducer {reducer_path_ex2} -input {data_small_path} -output {results_ex2_mapred_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> results/Ex2-MapRed/_SUCCESS <==\r\n",
      "\r\n",
      "==> results/Ex2-MapRed/part-00000 <==\r\n",
      "'Complex Disasters'\t[\"'Central America'\", \"'Eastern Asia'\", \"'Western Africa'\"]\r\n",
      "'Drought'\t[\"'Australia and New Zealand'\", \"'Eastern Europe'\", \"'Western Africa'\", \"'Western Asia'\"]\r\n",
      "'Earthquake'\t[\"'Central America'\", \"'Central Asia'\", \"'Micronesia'\", \"'Western Europe'\"]\r\n",
      "'Epidemic'\t[\"'Australia and New Zealand'\", \"'Central America'\", \"'Northern America'\", \"'Southern Africa'\", \"'Western Asia'\"]\r\n",
      "'Extreme temperature '\t[\"'Central America'\", \"'Eastern Europe'\", \"'Northern Africa'\", \"'Western Africa'\"]\r\n",
      "\r\n",
      "==> results/Ex2-MapRed/part-00001 <==\r\n",
      "'Complex Disasters'\t[\"'South-Eastern Asia'\", \"'Southern Asia'\"]\r\n",
      "'Drought'\t[\"'Middle Africa'\", \"'Russian Federation'\", \"'Southern Asia'\"]\r\n",
      "'Earthquake'\t[\"'Caribbean'\", \"'Eastern Africa'\", \"'Northern Europe'\", \"'South-Eastern Asia'\"]\r\n",
      "'Epidemic'\t[\"'Caribbean'\", \"'Micronesia'\"]\r\n",
      "'Extreme temperature '\t[\"'Northern Europe'\", \"'South-Eastern Asia'\", \"'Western Asia'\"]\r\n",
      "\r\n",
      "==> results/Ex2-MapRed/part-00002 <==\r\n",
      "'Complex Disasters'\t[\"'Western Asia'\"]\r\n",
      "'Drought'\t[\"'Northern Africa'\", \"'Northern America'\", \"'South America'\", \"'Southern Europe'\"]\r\n",
      "'Earthquake'\t[\"'Middle Africa'\", \"'Northern America'\", \"'Southern Africa'\", \"'Southern Asia'\", \"'Western Asia'\"]\r\n",
      "'Epidemic'\t[\"'Middle Africa'\", \"'Russian Federation'\", \"'South-Eastern Asia'\", \"'Western Europe'\"]\r\n",
      "'Extreme temperature '\t[\"'Australia and New Zealand'\", \"'Southern Africa'\"]\r\n",
      "\r\n",
      "==> results/Ex2-MapRed/part-00003 <==\r\n",
      "'Complex Disasters'\t[\"'Northern Africa'\"]\r\n",
      "'Drought'\t[\"'Caribbean'\", \"'Central Asia'\", \"'Eastern Asia'\", \"'Melanesia'\", \"'Micronesia'\", \"'Northern Europe'\", \"'Polynesia'\", \"'South-Eastern Asia'\", \"'Western Europe'\"]\r\n",
      "'Earthquake'\t[\"'Eastern Asia'\", \"'Melanesia'\", \"'Northern Africa'\", \"'Polynesia'\", \"'South America'\", \"'Southern Europe'\"]\r\n",
      "'Epidemic'\t[\"'Central Asia'\", \"'Eastern Africa'\", \"'Eastern Asia'\", \"'Melanesia'\", \"'Northern Africa'\", \"'Polynesia'\", \"'South America'\", \"'Southern Europe'\"]\r\n",
      "'Extreme temperature '\t[\"'Southern Asia'\", \"'Southern Europe'\", \"'Western Europe'\"]\r\n",
      "\r\n",
      "==> results/Ex2-MapRed/part-00004 <==\r\n",
      "'Animal accident'\t[\"'Western Africa'\"]\r\n",
      "'Complex Disasters'\t[\"'Eastern Africa'\", \"'Middle Africa'\", \"'Russian Federation'\"]\r\n",
      "'Drought'\t[\"'Central America'\", \"'Eastern Africa'\", \"'Southern Africa'\"]\r\n",
      "'Earthquake'\t[\"'Australia and New Zealand'\", \"'Eastern Europe'\", \"'Russian Federation'\", \"'Western Africa'\"]\r\n",
      "'Epidemic'\t[\"'Eastern Europe'\", \"'Northern Europe'\", \"'Southern Asia'\", \"'Western Africa'\"]\r\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "! head -n 5 {results_ex2_mapred_path}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Using an inverted index, solve: <br>\n",
    "\n",
    "What are the probabilities of getting injured or dying in a natural disaster of type T in the continent C\n",
    "during decade D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex3_mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%file {mapper_path_ex3}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "# Utility functions\n",
    "def Emit(key: str, value: str, sep='\\t'):\n",
    "    \"\"\"\n",
    "    Emmits a key-value pair.\n",
    "    \"\"\"\n",
    "    message = f'{key}' + sep + f'{value}'\n",
    "    print(message)\n",
    "\n",
    "def nan_to_zero(a: str)->int:\n",
    "    \"\"\"\n",
    "    Puts a zero string whenever the value is missing\n",
    "    \"\"\"\n",
    "    if not a:\n",
    "        return \"0\"\n",
    "    return a\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split(\",\")\n",
    "    \n",
    "    continent = words[5]\n",
    "    disaster = words[3]\n",
    "    decade = words[0][:3] + '0'\n",
    "    \n",
    "    casualties = [int(nan_to_zero(a)) for a in words[10:15]]\n",
    "    total_deaths, injured, affected, homeless, total_affected = casualties\n",
    "    \n",
    "    if total_affected < sum(casualties[:-1]):\n",
    "        total_affected = sum(casualties[:-1])\n",
    "    \n",
    "    print(f\"('{disaster}','{continent}','{decade}')\\t{[injured, total_deaths, total_affected]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/Ex3_reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%file {reducer_path_ex3}\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# import sys\n",
    "import sys\n",
    "# import string library function  \n",
    "import string \n",
    "\n",
    "# Utility functions\n",
    "def Emit(key: str, value: str, sep='\\t'):\n",
    "    \"\"\"\n",
    "    Emmits a key-value pair.\n",
    "    \"\"\"\n",
    "    message = f'{key}' + sep + f'{value}'\n",
    "    print(message)\n",
    "\n",
    "def calculate_probas(injured, deaths, total_affected):\n",
    "    \"\"\"\n",
    "    calculates probabilities of dying and being injured\n",
    "    regarding total_affected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sometimes there's no data and we \n",
    "    # don't want to divide by 0.\n",
    "    if injured == deaths == total_affected == 0:\n",
    "        death_proba = 0\n",
    "        injured_proba = 0\n",
    "    else:\n",
    "        death_proba = deaths / total_affected\n",
    "        injured_proba = injured / total_affected\n",
    "    return injured_proba, death_proba\n",
    "\n",
    "\n",
    "is_first = True\n",
    "curr_decade = ''\n",
    "curr_continent = ''\n",
    "curr_disaster = ''\n",
    "\n",
    "curr_total_affected = 0\n",
    "curr_total_deaths = 0\n",
    "curr_injured = 0\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into key,value\n",
    "    keys,values = line.split('\\t')\n",
    "    # separate compositeKey\n",
    "    continent, disaster, decade = eval(keys)\n",
    "    injured, total_deaths, total_affected = eval(values)\n",
    "    \n",
    "    if is_first:\n",
    "        is_first = False\n",
    "        curr_decade = decade\n",
    "        curr_continent = continent\n",
    "        curr_disaster = disaster\n",
    "        \n",
    "        curr_total_affected += total_affected\n",
    "        curr_total_deaths += total_deaths\n",
    "        curr_injured += injured\n",
    "        continue\n",
    "    \n",
    "    if decade != curr_decade or continent != curr_continent or disaster != curr_disaster:\n",
    "        \n",
    "        injured_proba, death_proba = \\\n",
    "            calculate_probas(curr_injured, curr_total_deaths, curr_total_affected)\n",
    "\n",
    "        print(f\"({disaster},{continent},{decade}),injured_proba: {injured_proba:.3f}\")\n",
    "        print(f\"({disaster},{continent},{decade}),death_proba: {death_proba:.3f})\")\n",
    "        \n",
    "        curr_decade = decade\n",
    "        curr_continent = continent\n",
    "        curr_disaster = disaster\n",
    "        \n",
    "        curr_total_affected = total_affected\n",
    "        curr_total_deaths = total_deaths\n",
    "        curr_injured = injured\n",
    "        continue\n",
    "# print the last one\n",
    "\n",
    "injured_proba, death_proba = \\\n",
    "    calculate_probas(curr_injured, curr_total_deaths, curr_total_affected)\n",
    "print(f\"({disaster},{continent},{decade}),injure_proba: {injured_proba:.3f}\")\n",
    "print(f\"({disaster},{continent},{decade}),death_proba: {death_proba:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:35:22,514 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2019-11-16 15:35:22,804 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2019-11-16 15:35:22,804 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2019-11-16 15:35:22,856 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-16 15:35:23,208 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2019-11-16 15:35:23,251 INFO mapreduce.JobSubmitter: number of splits:7\n",
      "2019-11-16 15:35:23,588 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local934547677_0001\n",
      "2019-11-16 15:35:23,588 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2019-11-16 15:35:23,815 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2019-11-16 15:35:23,821 INFO mapreduce.Job: Running job: job_local934547677_0001\n",
      "2019-11-16 15:35:23,823 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2019-11-16 15:35:23,836 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2019-11-16 15:35:23,845 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:23,846 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:23,962 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2019-11-16 15:35:23,980 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000000_0\n",
      "2019-11-16 15:35:24,069 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:24,074 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:24,127 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:24,162 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:0+33554432\n",
      "2019-11-16 15:35:24,208 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:24,283 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:24,284 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:24,284 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:24,284 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:24,284 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:24,308 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:24,332 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:24,360 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2019-11-16 15:35:24,361 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2019-11-16 15:35:24,362 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2019-11-16 15:35:24,362 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2019-11-16 15:35:24,364 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2019-11-16 15:35:24,364 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2019-11-16 15:35:24,364 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2019-11-16 15:35:24,365 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2019-11-16 15:35:24,365 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2019-11-16 15:35:24,367 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2019-11-16 15:35:24,367 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2019-11-16 15:35:24,368 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2019-11-16 15:35:24,431 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:24,433 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:24,441 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:24,484 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:24,507 INFO streaming.PipeMapRed: Records R/W=1282/1\n",
      "2019-11-16 15:35:24,727 INFO streaming.PipeMapRed: R/W/S=10000/7101/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:24,840 INFO mapreduce.Job: Job job_local934547677_0001 running in uber mode : false\n",
      "2019-11-16 15:35:24,844 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2019-11-16 15:35:25,985 INFO streaming.PipeMapRed: R/W/S=100000/97522/0 in:100000=100000/1 [rec/s] out:97523=97523/1 [rec/s]\n",
      "2019-11-16 15:35:27,315 INFO streaming.PipeMapRed: R/W/S=200000/197001/0 in:100000=200000/2 [rec/s] out:98500=197001/2 [rec/s]\n",
      "2019-11-16 15:35:28,563 INFO streaming.PipeMapRed: R/W/S=300000/297888/0 in:75000=300000/4 [rec/s] out:74472=297889/4 [rec/s]\n",
      "2019-11-16 15:35:28,805 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:28,828 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:28,836 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:28,836 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:28,836 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:28,836 INFO mapred.MapTask: bufstart = 0; bufend = 14380960; bufvoid = 104857600\n",
      "2019-11-16 15:35:28,836 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939532(99758128); length = 1274865/6553600\n",
      "2019-11-16 15:35:29,321 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:29,350 INFO mapred.Task: Task:attempt_local934547677_0001_m_000000_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:29,359 INFO mapred.LocalJobRunner: Records R/W=1282/1\n",
      "2019-11-16 15:35:29,359 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000000_0' done.\n",
      "2019-11-16 15:35:29,383 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33735999\n",
      "\t\tFILE: Number of bytes written=15711776\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318717\n",
      "\t\tMap output records=318717\n",
      "\t\tMap output bytes=14380960\n",
      "\t\tMap output materialized bytes=15018400\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318717\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=202375168\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:29,384 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000000_0\n",
      "2019-11-16 15:35:29,386 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000001_0\n",
      "2019-11-16 15:35:29,398 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:29,398 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:29,399 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:29,404 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:33554432+33554432\n",
      "2019-11-16 15:35:29,434 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:29,482 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:29,482 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:29,483 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:29,483 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:29,483 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:29,484 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:35:29,507 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:29,567 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:29,568 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:29,571 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:29,580 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:29,641 INFO streaming.PipeMapRed: Records R/W=1255/1\n",
      "2019-11-16 15:35:29,811 INFO streaming.PipeMapRed: R/W/S=10000/8337/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:29,858 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:30,940 INFO streaming.PipeMapRed: R/W/S=100000/97362/0 in:100000=100000/1 [rec/s] out:97363=97363/1 [rec/s]\n",
      "2019-11-16 15:35:32,165 INFO streaming.PipeMapRed: R/W/S=200000/196769/0 in:100000=200000/2 [rec/s] out:98385=196771/2 [rec/s]\n",
      "2019-11-16 15:35:33,404 INFO streaming.PipeMapRed: R/W/S=300000/297749/0 in:100000=300000/3 [rec/s] out:99249=297749/3 [rec/s]\n",
      "2019-11-16 15:35:33,665 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:33,688 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:33,689 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:33,689 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:33,689 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:33,689 INFO mapred.MapTask: bufstart = 0; bufend = 14379576; bufvoid = 104857600\n",
      "2019-11-16 15:35:33,689 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939868(99759472); length = 1274529/6553600\n",
      "2019-11-16 15:35:33,866 INFO mapreduce.Job:  map 14% reduce 0%\n",
      "2019-11-16 15:35:34,077 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:34,082 INFO mapred.Task: Task:attempt_local934547677_0001_m_000001_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:34,089 INFO mapred.LocalJobRunner: Records R/W=1255/1\n",
      "2019-11-16 15:35:34,089 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000001_0' done.\n",
      "2019-11-16 15:35:34,090 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67295264\n",
      "\t\tFILE: Number of bytes written=30728656\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318633\n",
      "\t\tMap output records=318633\n",
      "\t\tMap output bytes=14379576\n",
      "\t\tMap output materialized bytes=15016848\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318633\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=308805632\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:34,090 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000001_0\n",
      "2019-11-16 15:35:34,090 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000002_0\n",
      "2019-11-16 15:35:34,106 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:34,106 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:34,107 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:34,109 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:67108864+33554432\n",
      "2019-11-16 15:35:34,140 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:34,220 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:34,220 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:34,220 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:34,220 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:34,220 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:34,222 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:34,232 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:34,307 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:34,307 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:34,309 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:34,317 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:34,368 INFO streaming.PipeMapRed: Records R/W=1247/1\n",
      "2019-11-16 15:35:34,482 INFO streaming.PipeMapRed: R/W/S=10000/7845/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:34,867 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:35,739 INFO streaming.PipeMapRed: R/W/S=100000/98419/0 in:100000=100000/1 [rec/s] out:98421=98421/1 [rec/s]\n",
      "2019-11-16 15:35:37,028 INFO streaming.PipeMapRed: R/W/S=200000/198092/0 in:100000=200000/2 [rec/s] out:99046=198093/2 [rec/s]\n",
      "2019-11-16 15:35:38,220 INFO streaming.PipeMapRed: R/W/S=300000/297608/0 in:100000=300000/3 [rec/s] out:99203=297609/3 [rec/s]\n",
      "2019-11-16 15:35:38,571 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:38,574 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:38,575 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:38,575 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:38,575 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:38,575 INFO mapred.MapTask: bufstart = 0; bufend = 14377963; bufvoid = 104857600\n",
      "2019-11-16 15:35:38,575 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24939788(99759152); length = 1274609/6553600\n",
      "2019-11-16 15:35:38,874 INFO mapreduce.Job:  map 29% reduce 0%\n",
      "2019-11-16 15:35:38,959 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:38,968 INFO mapred.Task: Task:attempt_local934547677_0001_m_000002_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:38,979 INFO mapred.LocalJobRunner: Records R/W=1247/1\n",
      "2019-11-16 15:35:38,980 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000002_0' done.\n",
      "2019-11-16 15:35:38,982 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=100854529\n",
      "\t\tFILE: Number of bytes written=45743963\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318653\n",
      "\t\tMap output records=318653\n",
      "\t\tMap output bytes=14377963\n",
      "\t\tMap output materialized bytes=15015275\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318653\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=414187520\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:38,983 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000002_0\n",
      "2019-11-16 15:35:38,983 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000003_0\n",
      "2019-11-16 15:35:38,986 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:38,987 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:38,988 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:38,991 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:100663296+33554432\n",
      "2019-11-16 15:35:39,014 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:39,181 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:39,181 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:39,181 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:39,181 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:39,182 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:39,184 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:39,481 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:39,498 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:39,498 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:39,499 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:39,502 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:35:39,584 INFO streaming.PipeMapRed: Records R/W=1238/1\n",
      "2019-11-16 15:35:39,721 INFO streaming.PipeMapRed: R/W/S=10000/8101/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:39,875 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:40,985 INFO streaming.PipeMapRed: R/W/S=100000/98590/0 in:100000=100000/1 [rec/s] out:98590=98590/1 [rec/s]\n",
      "2019-11-16 15:35:42,967 INFO streaming.PipeMapRed: R/W/S=200000/197547/0 in:66666=200000/3 [rec/s] out:65849=197547/3 [rec/s]\n",
      "2019-11-16 15:35:44,998 INFO streaming.PipeMapRed: R/W/S=300000/298663/0 in:60000=300000/5 [rec/s] out:59732=298663/5 [rec/s]\n",
      "2019-11-16 15:35:45,447 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:45,455 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:45,460 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:45,462 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:45,463 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:45,466 INFO mapred.MapTask: bufstart = 0; bufend = 14380201; bufvoid = 104857600\n",
      "2019-11-16 15:35:45,466 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940072(99760288); length = 1274325/6553600\n",
      "2019-11-16 15:35:45,886 INFO mapreduce.Job:  map 43% reduce 0%\n",
      "2019-11-16 15:35:46,106 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:46,133 INFO mapred.Task: Task:attempt_local934547677_0001_m_000003_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:46,141 INFO mapred.LocalJobRunner: Records R/W=1238/1\n",
      "2019-11-16 15:35:46,142 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000003_0' done.\n",
      "2019-11-16 15:35:46,146 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=134413794\n",
      "\t\tFILE: Number of bytes written=60761366\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318582\n",
      "\t\tMap output records=318582\n",
      "\t\tMap output bytes=14380201\n",
      "\t\tMap output materialized bytes=15017371\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318582\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=359\n",
      "\t\tTotal committed heap usage (bytes)=332922880\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:46,147 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000003_0\n",
      "2019-11-16 15:35:46,154 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000004_0\n",
      "2019-11-16 15:35:46,128 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:46,128 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:46,129 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:46,137 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:134217728+33554432\n",
      "2019-11-16 15:35:46,210 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:46,264 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:46,264 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:46,264 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:46,264 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:46,265 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:46,270 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:46,296 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:46,338 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:46,338 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:46,339 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:46,341 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:46,456 INFO streaming.PipeMapRed: Records R/W=1247/1\n",
      "2019-11-16 15:35:46,656 INFO streaming.PipeMapRed: R/W/S=10000/9109/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:46,851 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:47,963 INFO streaming.PipeMapRed: R/W/S=100000/97492/0 in:100000=100000/1 [rec/s] out:97492=97492/1 [rec/s]\n",
      "2019-11-16 15:35:49,201 INFO streaming.PipeMapRed: R/W/S=200000/196988/0 in:100000=200000/2 [rec/s] out:98494=196988/2 [rec/s]\n",
      "2019-11-16 15:35:50,496 INFO streaming.PipeMapRed: R/W/S=300000/297616/0 in:75000=300000/4 [rec/s] out:74404=297616/4 [rec/s]\n",
      "2019-11-16 15:35:50,758 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:50,773 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:50,773 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:50,773 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:50,773 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:50,773 INFO mapred.MapTask: bufstart = 0; bufend = 14381055; bufvoid = 104857600\n",
      "2019-11-16 15:35:50,774 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940040(99760160); length = 1274357/6553600\n",
      "2019-11-16 15:35:50,858 INFO mapreduce.Job:  map 57% reduce 0%\n",
      "2019-11-16 15:35:51,131 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:51,136 INFO mapred.Task: Task:attempt_local934547677_0001_m_000004_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:51,144 INFO mapred.LocalJobRunner: Records R/W=1247/1\n",
      "2019-11-16 15:35:51,145 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000004_0' done.\n",
      "2019-11-16 15:35:51,146 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=167973059\n",
      "\t\tFILE: Number of bytes written=75779639\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318590\n",
      "\t\tMap output records=318590\n",
      "\t\tMap output bytes=14381055\n",
      "\t\tMap output materialized bytes=15018241\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318590\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=332922880\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:51,146 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000004_0\n",
      "2019-11-16 15:35:51,147 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000005_0\n",
      "2019-11-16 15:35:51,159 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:51,159 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:51,160 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:51,170 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:167772160+33554432\n",
      "2019-11-16 15:35:51,203 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:51,329 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:51,329 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:51,329 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:51,330 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:51,330 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:51,331 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:51,343 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:51,392 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:51,392 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:51,394 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:51,397 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:51,460 INFO streaming.PipeMapRed: Records R/W=1266/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:35:51,575 INFO streaming.PipeMapRed: R/W/S=10000/7837/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:51,860 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:52,703 INFO streaming.PipeMapRed: R/W/S=100000/97393/0 in:100000=100000/1 [rec/s] out:97393=97393/1 [rec/s]\n",
      "2019-11-16 15:35:53,957 INFO streaming.PipeMapRed: R/W/S=200000/197319/0 in:100000=200000/2 [rec/s] out:98659=197319/2 [rec/s]\n",
      "2019-11-16 15:35:56,047 INFO streaming.PipeMapRed: R/W/S=300000/298944/0 in:75000=300000/4 [rec/s] out:74736=298944/4 [rec/s]\n",
      "2019-11-16 15:35:56,571 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:56,573 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:56,573 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:56,574 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:56,574 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:56,574 INFO mapred.MapTask: bufstart = 0; bufend = 14381430; bufvoid = 104857600\n",
      "2019-11-16 15:35:56,574 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24940136(99760544); length = 1274261/6553600\n",
      "2019-11-16 15:35:56,868 INFO mapreduce.Job:  map 71% reduce 0%\n",
      "2019-11-16 15:35:56,981 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:56,989 INFO mapred.Task: Task:attempt_local934547677_0001_m_000005_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:57,000 INFO mapred.LocalJobRunner: Records R/W=1266/1\n",
      "2019-11-16 15:35:57,001 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000005_0' done.\n",
      "2019-11-16 15:35:57,007 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=201531812\n",
      "\t\tFILE: Number of bytes written=90798239\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=318566\n",
      "\t\tMap output records=318566\n",
      "\t\tMap output bytes=14381430\n",
      "\t\tMap output materialized bytes=15018568\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=318566\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=438304768\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "2019-11-16 15:35:57,008 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000005_0\n",
      "2019-11-16 15:35:57,009 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_m_000006_0\n",
      "2019-11-16 15:35:57,015 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:57,015 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:57,016 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:57,031 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/SPBD-Lab1/data/data_big.csv:201326592+4161225\n",
      "2019-11-16 15:35:57,066 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2019-11-16 15:35:57,272 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2019-11-16 15:35:57,272 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2019-11-16 15:35:57,272 INFO mapred.MapTask: soft limit at 83886080\n",
      "2019-11-16 15:35:57,272 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2019-11-16 15:35:57,272 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2019-11-16 15:35:57,274 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2019-11-16 15:35:57,351 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_mapper.py]\n",
      "2019-11-16 15:35:57,380 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:57,380 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:57,381 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:57,383 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:57,775 INFO streaming.PipeMapRed: Records R/W=2492/1\n",
      "2019-11-16 15:35:57,870 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2019-11-16 15:35:57,955 INFO streaming.PipeMapRed: R/W/S=10000/9022/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:35:58,454 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:35:58,461 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:35:58,462 INFO mapred.LocalJobRunner: \n",
      "2019-11-16 15:35:58,463 INFO mapred.MapTask: Starting flush of map output\n",
      "2019-11-16 15:35:58,463 INFO mapred.MapTask: Spilling map output\n",
      "2019-11-16 15:35:58,463 INFO mapred.MapTask: bufstart = 0; bufend = 1785146; bufvoid = 104857600\n",
      "2019-11-16 15:35:58,463 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26056448(104225792); length = 157949/6553600\n",
      "2019-11-16 15:35:58,517 INFO mapred.MapTask: Finished spill 0\n",
      "2019-11-16 15:35:58,522 INFO mapred.Task: Task:attempt_local934547677_0001_m_000006_0 is done. And is in the process of committing\n",
      "2019-11-16 15:35:58,528 INFO mapred.LocalJobRunner: Records R/W=2492/1\n",
      "2019-11-16 15:35:58,528 INFO mapred.Task: Task 'attempt_local934547677_0001_m_000006_0' done.\n",
      "2019-11-16 15:35:58,530 INFO mapred.Task: Final Counters for attempt_local934547677_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=205693262\n",
      "\t\tFILE: Number of bytes written=92662399\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=39488\n",
      "\t\tMap output records=39488\n",
      "\t\tMap output bytes=1785146\n",
      "\t\tMap output materialized bytes=1864128\n",
      "\t\tInput split bytes=102\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=39488\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=305\n",
      "\t\tTotal committed heap usage (bytes)=403177472\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4161225\n",
      "2019-11-16 15:35:58,530 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_m_000006_0\n",
      "2019-11-16 15:35:58,530 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2019-11-16 15:35:58,550 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2019-11-16 15:35:58,551 INFO mapred.LocalJobRunner: Starting task: attempt_local934547677_0001_r_000000_0\n",
      "2019-11-16 15:35:58,580 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2019-11-16 15:35:58,581 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2019-11-16 15:35:58,581 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2019-11-16 15:35:58,597 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3542b32e\n",
      "2019-11-16 15:35:58,604 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2019-11-16 15:35:58,661 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=326264416, maxSingleShuffleLimit=81566104, mergeThreshold=215334528, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2019-11-16 15:35:58,680 INFO reduce.EventFetcher: attempt_local934547677_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2019-11-16 15:35:58,763 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000000_0 decomp: 15018396 len: 15018400 to MEMORY\n",
      "2019-11-16 15:35:58,830 INFO reduce.InMemoryMapOutput: Read 15018396 bytes from map-output for attempt_local934547677_0001_m_000000_0\n",
      "2019-11-16 15:35:58,838 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15018396, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15018396\n",
      "2019-11-16 15:35:58,848 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000003_0 decomp: 15017367 len: 15017371 to MEMORY\n",
      "2019-11-16 15:35:58,893 INFO reduce.InMemoryMapOutput: Read 15017367 bytes from map-output for attempt_local934547677_0001_m_000003_0\n",
      "2019-11-16 15:35:58,893 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15017367, inMemoryMapOutputs.size() -> 2, commitMemory -> 15018396, usedMemory ->30035763\n",
      "2019-11-16 15:35:58,896 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000006_0 decomp: 1864124 len: 1864128 to MEMORY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:35:58,907 INFO reduce.InMemoryMapOutput: Read 1864124 bytes from map-output for attempt_local934547677_0001_m_000006_0\n",
      "2019-11-16 15:35:58,907 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1864124, inMemoryMapOutputs.size() -> 3, commitMemory -> 30035763, usedMemory ->31899887\n",
      "2019-11-16 15:35:58,914 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000002_0 decomp: 15015271 len: 15015275 to MEMORY\n",
      "2019-11-16 15:35:58,960 INFO reduce.InMemoryMapOutput: Read 15015271 bytes from map-output for attempt_local934547677_0001_m_000002_0\n",
      "2019-11-16 15:35:58,961 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15015271, inMemoryMapOutputs.size() -> 4, commitMemory -> 31899887, usedMemory ->46915158\n",
      "2019-11-16 15:35:58,967 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000005_0 decomp: 15018564 len: 15018568 to MEMORY\n",
      "2019-11-16 15:35:58,978 INFO reduce.InMemoryMapOutput: Read 15018564 bytes from map-output for attempt_local934547677_0001_m_000005_0\n",
      "2019-11-16 15:35:58,978 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15018564, inMemoryMapOutputs.size() -> 5, commitMemory -> 46915158, usedMemory ->61933722\n",
      "2019-11-16 15:35:58,984 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000004_0 decomp: 15018237 len: 15018241 to MEMORY\n",
      "2019-11-16 15:35:58,994 INFO reduce.InMemoryMapOutput: Read 15018237 bytes from map-output for attempt_local934547677_0001_m_000004_0\n",
      "2019-11-16 15:35:58,994 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15018237, inMemoryMapOutputs.size() -> 6, commitMemory -> 61933722, usedMemory ->76951959\n",
      "2019-11-16 15:35:59,059 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934547677_0001_m_000001_0 decomp: 15016844 len: 15016848 to MEMORY\n",
      "2019-11-16 15:35:59,093 INFO reduce.InMemoryMapOutput: Read 15016844 bytes from map-output for attempt_local934547677_0001_m_000001_0\n",
      "2019-11-16 15:35:59,093 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15016844, inMemoryMapOutputs.size() -> 7, commitMemory -> 76951959, usedMemory ->91968803\n",
      "2019-11-16 15:35:59,095 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2019-11-16 15:35:59,099 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "2019-11-16 15:35:59,100 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2019-11-16 15:35:59,118 INFO mapred.Merger: Merging 7 sorted segments\n",
      "2019-11-16 15:35:59,119 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 91968537 bytes\n",
      "2019-11-16 15:36:00,531 INFO reduce.MergeManagerImpl: Merged 7 segments, 91968803 bytes to disk to satisfy reduce memory limit\n",
      "2019-11-16 15:36:00,531 INFO reduce.MergeManagerImpl: Merging 1 files, 91968795 bytes from disk\n",
      "2019-11-16 15:36:00,533 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2019-11-16 15:36:00,533 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2019-11-16 15:36:00,534 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 91968753 bytes\n",
      "2019-11-16 15:36:00,536 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "2019-11-16 15:36:00,556 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/SPBD-Lab1/./scripts/Ex3_reducer.py]\n",
      "2019-11-16 15:36:00,567 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2019-11-16 15:36:00,567 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2019-11-16 15:36:00,670 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:36:00,671 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:36:00,673 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:36:00,747 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:36:01,141 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2019-11-16 15:36:03,743 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:33333=100000/3 [rec/s] out:0=0/3 [rec/s]\n",
      "2019-11-16 15:36:06,268 INFO streaming.PipeMapRed: Records R/W=192261/1\n",
      "2019-11-16 15:36:06,496 INFO streaming.PipeMapRed: R/W/S=200000/182/0 in:40000=200000/5 [rec/s] out:36=182/5 [rec/s]\n",
      "2019-11-16 15:36:09,496 INFO streaming.PipeMapRed: R/W/S=300000/182/0 in:37500=300000/8 [rec/s] out:22=182/8 [rec/s]\n",
      "2019-11-16 15:36:10,596 INFO mapred.LocalJobRunner: Records R/W=192261/1 > reduce\n",
      "2019-11-16 15:36:10,889 INFO mapreduce.Job:  map 100% reduce 72%\n",
      "2019-11-16 15:36:12,106 INFO streaming.PipeMapRed: R/W/S=400000/182/0 in:36363=400000/11 [rec/s] out:16=182/11 [rec/s]\n",
      "2019-11-16 15:36:14,401 INFO streaming.PipeMapRed: R/W/S=500000/354/0 in:38461=500000/13 [rec/s] out:27=354/13 [rec/s]\n",
      "2019-11-16 15:36:16,567 INFO mapred.LocalJobRunner: Records R/W=192261/1 > reduce\n",
      "2019-11-16 15:36:16,781 INFO streaming.PipeMapRed: R/W/S=600000/354/0 in:37500=600000/16 [rec/s] out:22=354/16 [rec/s]\n",
      "2019-11-16 15:36:16,867 INFO mapreduce.Job:  map 100% reduce 76%\n",
      "2019-11-16 15:36:19,040 INFO streaming.PipeMapRed: R/W/S=700000/354/0 in:38888=700000/18 [rec/s] out:19=354/18 [rec/s]\n",
      "2019-11-16 15:36:21,289 INFO streaming.PipeMapRed: R/W/S=800000/354/0 in:40000=800000/20 [rec/s] out:17=354/20 [rec/s]\n",
      "2019-11-16 15:36:22,569 INFO mapred.LocalJobRunner: Records R/W=192261/1 > reduce\n",
      "2019-11-16 15:36:22,878 INFO mapreduce.Job:  map 100% reduce 80%\n",
      "2019-11-16 15:36:23,487 INFO streaming.PipeMapRed: R/W/S=900000/354/0 in:40909=900000/22 [rec/s] out:16=354/22 [rec/s]\n",
      "2019-11-16 15:36:24,514 INFO streaming.PipeMapRed: Records R/W=946503/355\n",
      "2019-11-16 15:36:25,669 INFO streaming.PipeMapRed: R/W/S=1000000/529/0 in:40000=1000000/25 [rec/s] out:21=529/25 [rec/s]\n",
      "2019-11-16 15:36:27,966 INFO streaming.PipeMapRed: R/W/S=1100000/695/0 in:40740=1100000/27 [rec/s] out:25=695/27 [rec/s]\n",
      "2019-11-16 15:36:28,570 INFO mapred.LocalJobRunner: Records R/W=946503/355 > reduce\n",
      "2019-11-16 15:36:28,887 INFO mapreduce.Job:  map 100% reduce 85%\n",
      "2019-11-16 15:36:30,166 INFO streaming.PipeMapRed: R/W/S=1200000/695/0 in:41379=1200000/29 [rec/s] out:23=695/29 [rec/s]\n",
      "2019-11-16 15:36:32,344 INFO streaming.PipeMapRed: R/W/S=1300000/695/0 in:41935=1300000/31 [rec/s] out:22=695/31 [rec/s]\n",
      "2019-11-16 15:36:34,503 INFO streaming.PipeMapRed: R/W/S=1400000/695/0 in:42424=1400000/33 [rec/s] out:21=695/33 [rec/s]\n",
      "2019-11-16 15:36:34,571 INFO mapred.LocalJobRunner: Records R/W=946503/355 > reduce\n",
      "2019-11-16 15:36:34,895 INFO mapreduce.Job:  map 100% reduce 90%\n",
      "2019-11-16 15:36:35,369 INFO streaming.PipeMapRed: Records R/W=1441940/696\n",
      "2019-11-16 15:36:36,874 INFO streaming.PipeMapRed: R/W/S=1500000/862/0 in:41666=1500000/36 [rec/s] out:23=862/36 [rec/s]\n",
      "2019-11-16 15:36:39,212 INFO streaming.PipeMapRed: R/W/S=1600000/862/0 in:42105=1600000/38 [rec/s] out:22=862/38 [rec/s]\n",
      "2019-11-16 15:36:40,574 INFO mapred.LocalJobRunner: Records R/W=1441940/696 > reduce\n",
      "2019-11-16 15:36:40,903 INFO mapreduce.Job:  map 100% reduce 95%\n",
      "2019-11-16 15:36:41,415 INFO streaming.PipeMapRed: R/W/S=1700000/862/0 in:42500=1700000/40 [rec/s] out:21=862/40 [rec/s]\n",
      "2019-11-16 15:36:43,674 INFO streaming.PipeMapRed: R/W/S=1800000/862/0 in:41860=1800000/43 [rec/s] out:20=862/43 [rec/s]\n",
      "2019-11-16 15:36:45,837 INFO streaming.PipeMapRed: Records R/W=1896904/863\n",
      "2019-11-16 15:36:45,902 INFO streaming.PipeMapRed: R/W/S=1900000/1020/0 in:42222=1900000/45 [rec/s] out:22=1020/45 [rec/s]\n",
      "2019-11-16 15:36:46,543 INFO mapred.LocalJobRunner: Records R/W=1896904/863 > reduce\n",
      "2019-11-16 15:36:46,880 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2019-11-16 15:36:47,078 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2019-11-16 15:36:47,079 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2019-11-16 15:36:47,085 INFO mapred.Task: Task:attempt_local934547677_0001_r_000000_0 is done. And is in the process of committing\n",
      "2019-11-16 15:36:47,093 INFO mapred.LocalJobRunner: Records R/W=1896904/863 > reduce\n",
      "2019-11-16 15:36:47,093 INFO mapred.Task: Task attempt_local934547677_0001_r_000000_0 is allowed to commit now\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 15:36:47,138 INFO output.FileOutputCommitter: Saved output of task 'attempt_local934547677_0001_r_000000_0' to file:/home/jovyan/work/SPBD-Lab1/results/Ex3-MapRed\n",
      "2019-11-16 15:36:47,141 INFO mapred.LocalJobRunner: Records R/W=1896904/863 > reduce\n",
      "2019-11-16 15:36:47,141 INFO mapred.Task: Task 'attempt_local934547677_0001_r_000000_0' done.\n",
      "2019-11-16 15:36:47,148 INFO mapred.Task: Final Counters for attempt_local934547677_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=389631112\n",
      "\t\tFILE: Number of bytes written=184688218\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=575\n",
      "\t\tReduce shuffle bytes=91968831\n",
      "\t\tReduce input records=1951229\n",
      "\t\tReduce output records=1150\n",
      "\t\tSpilled Records=1951229\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=102\n",
      "\t\tTotal committed heap usage (bytes)=351272960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=57024\n",
      "2019-11-16 15:36:47,150 INFO mapred.LocalJobRunner: Finishing task: attempt_local934547677_0001_r_000000_0\n",
      "2019-11-16 15:36:47,150 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2019-11-16 15:36:47,884 INFO mapreduce.Job: Job job_local934547677_0001 completed successfully\n",
      "2019-11-16 15:36:47,943 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1301128831\n",
      "\t\tFILE: Number of bytes written=596874256\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1951229\n",
      "\t\tMap output records=1951229\n",
      "\t\tMap output bytes=88066331\n",
      "\t\tMap output materialized bytes=91968831\n",
      "\t\tInput split bytes=714\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=575\n",
      "\t\tReduce shuffle bytes=91968831\n",
      "\t\tReduce input records=1951229\n",
      "\t\tReduce output records=1150\n",
      "\t\tSpilled Records=3902458\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=789\n",
      "\t\tTotal committed heap usage (bytes)=2783969280\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=205512393\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=57024\n",
      "2019-11-16 15:36:47,946 INFO streaming.StreamJob: Output directory: results/Ex3-MapRed\n",
      "CPU times: user 2.47 s, sys: 1.4 s, total: 3.87 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! chmod a+x {mapper_path_ex3} && chmod a+x {reducer_path_ex3}\n",
    "! rm -rf {results_ex3_mapred_path}\n",
    "! hadoop jar /opt/hadoop-3.2.0/share/hadoop/tools/lib/hadoop-*streaming*.jar -mapper {mapper_path_ex3} -reducer {reducer_path_ex3} -input {data_big_path} -output {results_ex3_mapred_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> results/Ex3-MapRed/_SUCCESS <==\r\n",
      "\r\n",
      "==> results/Ex3-MapRed/part-00000 <==\r\n",
      "(Africa,Complex Disasters,1970),injured_proba: 0.000\t\r\n",
      "(Africa,Complex Disasters,1970),death_proba: 0.444)\t\r\n",
      "(Africa,Complex Disasters,1990),injured_proba: 0.000\t\r\n",
      "(Africa,Complex Disasters,1990),death_proba: 0.000)\t\r\n",
      "(Africa,Complex Disasters,2000),injured_proba: 0.000\t\r\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "! head -n 5 {results_ex3_mapred_path}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technology: Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!rm -rf {output_sql_ex1_path}\n",
    "\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from IPython.display import display\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Ex1').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try :\n",
    "    lines = sc.textFile(data_small_path)\n",
    "    continent_occurences = lines.map( lambda line : line.split(',') ) \\\n",
    "                   .map( lambda arr : Row( continent = arr[5], occurences = int(arr[9])))\n",
    "    continent_occurences_df = spark.createDataFrame( continent_occurences )\n",
    "    continent_occurences_df.createOrReplaceTempView(\"continents\")\n",
    "    \n",
    "    query = (\"SELECT continent,SUM(occurences) as n_occurences from continents \"\n",
    "             \"Group by continent\")\n",
    "    InvIdxContinentOccurencesDF = spark.sql(query)\n",
    "    InvIdxContinentOccurencesDF.write.csv(output_sql_ex1_path)\n",
    "    sc.stop()\n",
    "except:\n",
    "    print(err)\n",
    "    sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
